{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd077b122b46b811bf25a94c2daf71b0b6b5d8e93bff1d9be67645d638b69bd8036",
   "display_name": "Python 3.7.3 64-bit ('ds21_capstone': virtualenvwrapper)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Modeling Part 1 -- Linear Regression\n",
    "---\n",
    "\n",
    "With the data now cleaned, we are going to start simple with a linear regression model to build a performance baseline. Due to the nature of our data being almost entirely categorical/ordinal, we do not expect this to perform well, even with Lasso (L1) regularization.\n",
    "\n",
    "Our baseline will be calculated using `api_delta` only (calculated difference of API score between post and pre treatment).\n",
    "\n",
    "To make life easier, we will use the data that does not included missing values.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Packages + Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# stats models\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned/not_scaled_no_missing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making all columns numeric again \n",
    "# Writing to CSV sometimes mucks with data types :(\n",
    "cols = df.columns\n",
    "\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(184, 129)"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "# expect 184 records if dropping all NAs\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Create target dataframe (difference between scores)\n",
    "df_target = df[['study_group', 'cluster2019_base']]\n",
    "df_target['api_delta'] = df['api_tot_recode0_4_post'] - df['api_tot_recode0_4_base']\n",
    "df_target['csigi_delta'] = df['csigimn2019_post'] - df['csigimn2019_base']\n",
    "df_target['cprinter_delta'] = df['cprinterf8_post'] - df['cprinterf8_base']\n",
    "\n",
    "# Drop \n",
    "df = df.drop(\n",
    "    ['api_tot_recode0_4_post', 'csigimn2019_post', 'cprinterf8_post', 'cprint8_tscore_post',\n",
    "     'cluster2019_base', 'api_tot_recode0_4_base', 'csigimn2019_base',\n",
    "    'cprinterf8_base', 'cprint8_tscore_base'\n",
    "    ],\n",
    "\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "source": [
    "## Linear Regression (statsmodels)\n",
    "---\n",
    "\n",
    "Using mean absolute error (MAE) becuase the difference from pre-to-post score can be a decimal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, \n",
    "    df_target['api_delta'],\n",
    "    test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression Model\n",
    "\n",
    "# Add intercept + rename\n",
    "# ref: https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS\n",
    "sm_reg = sm.add_constant(X_train)\n",
    "sm_reg = sm_reg.rename(columns={'const': 'intercept'})\n",
    "\n",
    "est = sm.OLS(y_train, sm_reg)\n",
    "model_linReg = est.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Predictions\n",
    "X_test = sm.add_constant(X_test)\n",
    "predictions = model_linReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE (statsmodels) -- 3.12\nMAE (statsmodels) -- 1.32\n"
     ]
    }
   ],
   "source": [
    "# MSE \n",
    "sm_mse = ((y_test - predictions)**2).sum() / len(predictions)\n",
    "sm_mae = abs(y_test - predictions).sum() / len(predictions)\n",
    "\n",
    "print(f'MSE (statsmodels) -- {round(sm_mse, 2)}')\n",
    "print(f'MAE (statsmodels) -- {round(sm_mae, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              api_delta   R-squared:                       0.938\nModel:                            OLS   Adj. R-squared:                  0.503\nMethod:                 Least Squares   F-statistic:                     2.156\nDate:                Sun, 02 May 2021   Prob (F-statistic):             0.0358\nTime:                        21:27:54   Log-Likelihood:                 7.4919\nNo. Observations:                 138   AIC:                             227.0\nDf Residuals:                      17   BIC:                             581.2\nDf Model:                         120                                         \nCovariance Type:            nonrobust                                         \n=====================================================================================\n                        coef    std err          t      P>|t|      [0.025      0.975]\n-------------------------------------------------------------------------------------\nintercept             5.6339      2.738      2.057      0.055      -0.143      11.411\nstudy_group          -0.1972      0.139     -1.423      0.173      -0.490       0.095\nage_consent           0.0169      0.089      0.190      0.851      -0.170       0.204\nsex                  -1.0431      0.344     -3.031      0.008      -1.769      -0.317\napi1_txfap           -0.4718      0.178     -2.647      0.017      -0.848      -0.096\napi2_txfap            0.2189      0.209      1.048      0.310      -0.222       0.660\napi3_txfap           -0.1657      0.099     -1.669      0.113      -0.375       0.044\napi4_txfap           -0.0592      0.108     -0.547      0.591      -0.287       0.169\napi5_txfap            0.0846      0.098      0.860      0.402      -0.123       0.292\ncsi1_txfap           -0.2553      0.194     -1.315      0.206      -0.665       0.154\ncsi2_txfap            0.1464      0.156      0.937      0.362      -0.183       0.476\ncsi3_txfap           -0.2669      0.190     -1.408      0.177      -0.667       0.133\ncsi4_txfap           -0.3317      0.193     -1.721      0.103      -0.738       0.075\ncsi5_txfap           -0.2435      0.222     -1.096      0.288      -0.712       0.225\ncsi6_txfap            0.0149      0.213      0.070      0.945      -0.434       0.464\ncsi7_txfap           -0.3089      0.244     -1.268      0.222      -0.823       0.205\ncsi8_txfap            0.4670      0.162      2.876      0.010       0.124       0.810\ncsi9_txfap            0.2613      0.254      1.028      0.318      -0.275       0.798\ncsi10_txfap           0.1594      0.239      0.668      0.513      -0.344       0.663\ncsi11_txfap           0.1777      0.268      0.662      0.517      -0.389       0.744\ncsi12_txfap          -0.0582      0.199     -0.293      0.773      -0.478       0.362\ncsi13_txfap          -0.2703      0.143     -1.895      0.075      -0.571       0.031\ncsi14_txfap           0.1429      0.167      0.855      0.405      -0.210       0.496\ncsi15_txfap          -0.0913      0.213     -0.428      0.674      -0.542       0.359\ncsi16_txfap           0.1288      0.166      0.776      0.449      -0.222       0.479\ncsi17_txfap           0.0247      0.195      0.127      0.901      -0.387       0.436\ncsi18_txfap          -0.1488      0.215     -0.692      0.498      -0.602       0.305\ncsi19_txfap          -0.1120      0.207     -0.540      0.596      -0.550       0.326\ncsi20_txfap          -0.0474      0.151     -0.314      0.757      -0.366       0.271\ncsi21_txfap          -0.1438      0.155     -0.928      0.366      -0.471       0.183\ncsi22_txfap           0.1971      0.170      1.162      0.261      -0.161       0.555\ncsi23_txfap           0.0508      0.236      0.215      0.832      -0.448       0.549\ncsi24_txfap          -0.1200      0.282     -0.425      0.676      -0.716       0.476\nfdi2_txfap           -0.2600      0.284     -0.916      0.372      -0.859       0.339\nfdi3_txfap            0.2527      0.194      1.300      0.211      -0.157       0.663\nfdi4_txfap           -0.4750      0.324     -1.468      0.160      -1.158       0.208\nfdi5_txfap            0.0260      0.210      0.124      0.903      -0.418       0.470\nfdi8_txfap           -0.0241      0.197     -0.122      0.904      -0.440       0.392\nfdi9_txfap           -0.1277      0.203     -0.628      0.538      -0.556       0.301\nfdi10_txfap          -0.4113      0.236     -1.744      0.099      -0.909       0.086\nfdi12_txfap           0.5617      0.356      1.577      0.133      -0.190       1.313\nfdi13_txfap          -0.0339      0.235     -0.144      0.887      -0.530       0.462\nfdi14_txfap           0.1477      0.192      0.771      0.451      -0.257       0.552\ncdi1_txfap           -0.2238      0.433     -0.517      0.612      -1.138       0.690\ncdi2_txfap           -0.3439      0.364     -0.945      0.358      -1.111       0.424\ncdi3_txfap           -0.1814      0.407     -0.445      0.662      -1.041       0.678\ncdi4_txfap            0.1621      0.295      0.549      0.590      -0.461       0.785\ncdi5_txfap            0.9120      0.461      1.976      0.065      -0.062       1.886\ncdi6_txfap            0.1626      0.340      0.478      0.639      -0.555       0.880\ncdi7_txfap            0.5589      0.550      1.017      0.324      -0.601       1.719\ncdi8_txfap           -0.1117      0.417     -0.268      0.792      -0.992       0.768\ncdi9_txfap            0.5378      0.282      1.908      0.073      -0.057       1.132\ncdi10_txfap           0.2914      0.316      0.921      0.370      -0.376       0.958\ncdi11_txfap           0.2573      0.374      0.688      0.501      -0.531       1.046\ncdi12_txfap           0.1283      0.299      0.429      0.673      -0.503       0.759\ncdi13_txfap          -0.2946      0.315     -0.935      0.363      -0.960       0.370\ncdi14_txfap           0.2198      0.245      0.896      0.383      -0.298       0.737\ncdi15_txfap           0.1567      0.462      0.339      0.739      -0.819       1.132\ncdi16_txfap          -0.3084      0.239     -1.291      0.214      -0.812       0.196\ncdi17_txfap           0.0669      0.214      0.313      0.758      -0.384       0.518\ncdi18_txfap          -0.0174      0.347     -0.050      0.961      -0.749       0.714\ncdi19_txfap           0.1359      0.388      0.350      0.730      -0.683       0.955\ncdi20_txfap          -0.0961      0.265     -0.363      0.721      -0.655       0.463\ncdi21_txfap          -0.5147      0.304     -1.693      0.109      -1.156       0.127\ncdi22_txfap          -0.4158      0.266     -1.562      0.137      -0.978       0.146\ncdi23_txfap          -0.3046      0.269     -1.133      0.273      -0.872       0.263\ncdi24_txfap          -0.2700      0.478     -0.564      0.580      -1.279       0.739\ncdi25_txfap          -0.0103      0.393     -0.026      0.979      -0.840       0.820\ncdi26_txfap           0.0341      0.494      0.069      0.946      -1.007       1.075\npbq1_txfap            0.3284      0.171      1.917      0.072      -0.033       0.690\npbq2_txfap            0.1601      0.169      0.948      0.356      -0.196       0.516\npbq3_txfap           -0.1112      0.149     -0.746      0.466      -0.426       0.203\npbq4_txfap            0.1457      0.194      0.749      0.464      -0.265       0.556\npbq5_txfap           -0.0067      0.134     -0.050      0.961      -0.289       0.275\npbq6_txfap           -0.1372      0.128     -1.075      0.298      -0.407       0.132\npbq7_txfap            0.0442      0.167      0.265      0.794      -0.307       0.396\npbq8_txfap           -0.0730      0.169     -0.432      0.671      -0.429       0.283\npbq9_txfap           -0.2798      0.144     -1.939      0.069      -0.584       0.025\npbq10_txfap           0.0095      0.163      0.058      0.954      -0.335       0.353\npbq11_txfap          -0.0215      0.156     -0.138      0.892      -0.351       0.308\npbq12_txfap          -0.0116      0.191     -0.061      0.952      -0.415       0.392\npbq13_txfap          -0.2724      0.218     -1.251      0.228      -0.732       0.187\npbq14_txfap           0.0772      0.148      0.521      0.609      -0.235       0.389\npbq15_txfap          -0.1721      0.205     -0.840      0.413      -0.604       0.260\npbq16_txfap           0.1172      0.196      0.599      0.557      -0.296       0.530\npbq17_txfap           0.1559      0.212      0.736      0.472      -0.291       0.603\npbq18_txfap          -0.0197      0.252     -0.078      0.939      -0.551       0.512\npri11_txfap          -0.0984      0.231     -0.427      0.675      -0.585       0.388\npri12_txfap           0.0074      0.193      0.039      0.970      -0.400       0.415\npri13_txfap          -0.1130      0.221     -0.511      0.616      -0.580       0.354\npri14_txfap           0.0760      0.247      0.308      0.762      -0.444       0.596\npri15_txfap          -0.0117      0.193     -0.061      0.952      -0.419       0.395\npcsc1_txfap          -0.1535      0.201     -0.765      0.455      -0.577       0.270\npcsc2_txfap           0.3379      0.228      1.483      0.157      -0.143       0.819\npcsc3_txfap          -0.1596      0.271     -0.590      0.563      -0.731       0.412\npcsc4_txfap           0.3369      0.246      1.367      0.189      -0.183       0.857\npcsc5_txfap           0.0057      0.227      0.025      0.980      -0.474       0.486\npcsc6_txfap          -0.1925      0.186     -1.032      0.316      -0.586       0.201\npcsc7_txfap           0.1416      0.198      0.715      0.485      -0.276       0.560\npcsc8_txfap           0.0691      0.199      0.346      0.733      -0.352       0.490\npcsc9_txfap           0.1334      0.160      0.833      0.416      -0.205       0.471\npcsc10_txfap         -0.5256      0.242     -2.169      0.045      -1.037      -0.014\npcsc11_txfap         -0.0149      0.183     -0.081      0.936      -0.402       0.372\npcsc12_txfap         -0.3416      0.195     -1.754      0.097      -0.752       0.069\npcsc13_txfap          0.1738      0.189      0.921      0.370      -0.224       0.572\npromis_anx1_txfap     0.1220      0.254      0.481      0.637      -0.413       0.657\npromis_anx2_txfap    -0.1712      0.269     -0.637      0.533      -0.739       0.396\npromis_anx3_txfap    -0.1664      0.251     -0.663      0.516      -0.695       0.363\npromis_anx4_txfap     0.1307      0.220      0.595      0.560      -0.333       0.594\npromis_anx5_txfap     0.1515      0.190      0.797      0.436      -0.249       0.552\npromis_anx6_txfap    -0.0825      0.215     -0.384      0.706      -0.536       0.371\npromis_anx7_txfap     0.1758      0.246      0.714      0.485      -0.344       0.696\npromis_anx8_txfap    -0.2224      0.202     -1.102      0.286      -0.648       0.204\nprsleep1_txfap       -0.2035      0.213     -0.954      0.354      -0.654       0.247\nprsleep2_txfap       -0.0824      0.164     -0.503      0.621      -0.428       0.263\nprsleep3_txfap       -0.0459      0.151     -0.304      0.765      -0.365       0.273\nprsleep4_txfap        0.1340      0.195      0.687      0.501      -0.277       0.545\nprsleep5_txfap       -0.1979      0.217     -0.911      0.375      -0.656       0.260\nprsleep6_txfap       -0.1081      0.316     -0.342      0.737      -0.775       0.559\nprsleep7_txfap       -0.1367      0.157     -0.871      0.396      -0.468       0.194\nprsleep8_txfap       -0.4411      0.340     -1.297      0.212      -1.159       0.276\n==============================================================================\nOmnibus:                        4.114   Durbin-Watson:                   2.007\nProb(Omnibus):                  0.128   Jarque-Bera (JB):                4.379\nSkew:                          -0.190   Prob(JB):                        0.112\nKurtosis:                       3.786   Cond. No.                     1.23e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.23e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "print(model_linReg.summary())"
   ]
  },
  {
   "source": [
    "## Lasso Regression + Mutual Info Regression\n",
    "---\n",
    "\n",
    "Lasso regression to select features. Copying down some data work so we can execute multiple iterations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for Lasso\n",
    "df_lasso = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# -------------------------------\n",
    "iters = 5\n",
    "seeds = random.sample(range(10000), iters)\n",
    "alpha = np.arange(0.01, 0.16, 0.01).tolist()\n",
    "\n",
    "iterations = list(itertools.product(*[seeds, alpha]))\n",
    "\n",
    "# Store Results\n",
    "feature_coefs = []\n",
    "model_results = []  # alpha, mse, mae, r^2\n",
    "predictions = []\n",
    "target_idx = []\n",
    "mutual_info_reg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(iterations)):\n",
    "\n",
    "    a = iterations[i][1]\n",
    "\n",
    "    # Split the data (seed based on i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_lasso, \n",
    "        df_target['api_delta'],\n",
    "        test_size=0.25,\n",
    "        random_state = iterations[i][0]\n",
    "    )\n",
    "\n",
    "    # Normalize data based on training\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform training data\n",
    "    X_train_scale = pd.DataFrame(scaler.transform(X_train))\n",
    "    X_train_scale.columns = X_train.columns\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_scale = pd.DataFrame(scaler.transform(X_test))\n",
    "    X_test_scale.columns = X_test.columns\n",
    "\n",
    "    # -----------------\n",
    "    # MODELING STARTS HERE\n",
    "    # -----------------\n",
    "    clf = linear_model.Lasso(alpha = a)\n",
    "    model = clf.fit(X_train_scale, y_train)\n",
    "\n",
    "    # Mutual Information Regression\n",
    "    mir = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "    mir.fit(X_train_scale, y_train);\n",
    "    \n",
    "    # Predictions\n",
    "    prediction_lasso = model.predict(X_test_scale)\n",
    "\n",
    "    # model metrics\n",
    "    mse = mean_squared_error(y_test, prediction_lasso)\n",
    "    mae = mean_absolute_error(y_test, prediction_lasso)\n",
    "    r2 = r2_score(y_test, prediction_lasso)\n",
    "\n",
    "    # Store details\n",
    "    feature_coefs.append(model.coef_)\n",
    "    model_results.append([a, mse, mae, r2])\n",
    "    predictions.append(list(prediction_lasso))\n",
    "    target_idx.append(list(y_test.index))\n",
    "    mutual_info_reg.append(mir.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Importance\n",
    "df_lasso_results = pd.DataFrame(\n",
    "    model_results,\n",
    "    columns = ['alpha', 'mse', 'mae', 'r2']\n",
    ")\n",
    "\n",
    "# Feature Coefficiencts\n",
    "df_lasso_coefs = pd.DataFrame(\n",
    "    feature_coefs,\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "df_mir = pd.DataFrame(\n",
    "    mutual_info_reg,\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "# Combine them!\n",
    "df_results = pd.concat([df_lasso_results, df_lasso_coefs], axis=1)\n",
    "df_mir = pd.concat([df_lasso_results, df_mir], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  alpha    mae                   r2              \n",
       "          mean median    min   mean median    min\n",
       "0  0.01  0.743  0.739  0.724  0.101  0.035 -0.033\n",
       "1  0.02  0.724  0.717  0.693  0.169  0.144  0.082\n",
       "2  0.03  0.711  0.708  0.674  0.196  0.184  0.127\n",
       "3  0.04  0.724  0.716  0.669  0.176  0.168  0.147\n",
       "4  0.05  0.739  0.729  0.669  0.147  0.147  0.123"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>alpha</th>\n      <th colspan=\"3\" halign=\"left\">mae</th>\n      <th colspan=\"3\" halign=\"left\">r2</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>median</th>\n      <th>min</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>0.743</td>\n      <td>0.739</td>\n      <td>0.724</td>\n      <td>0.101</td>\n      <td>0.035</td>\n      <td>-0.033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02</td>\n      <td>0.724</td>\n      <td>0.717</td>\n      <td>0.693</td>\n      <td>0.169</td>\n      <td>0.144</td>\n      <td>0.082</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.03</td>\n      <td>0.711</td>\n      <td>0.708</td>\n      <td>0.674</td>\n      <td>0.196</td>\n      <td>0.184</td>\n      <td>0.127</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.04</td>\n      <td>0.724</td>\n      <td>0.716</td>\n      <td>0.669</td>\n      <td>0.176</td>\n      <td>0.168</td>\n      <td>0.147</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.05</td>\n      <td>0.739</td>\n      <td>0.729</td>\n      <td>0.669</td>\n      <td>0.147</td>\n      <td>0.147</td>\n      <td>0.123</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "# BEST LASSO RESULTS --- alpha is 0.03 or 0.04\n",
    "df_results[['alpha', 'mae', 'r2']].groupby('alpha').agg(['mean', 'median', 'min']).reset_index().head().round(3)"
   ]
  },
  {
   "source": [
    "#### Repeating With Alpha = 0.03\n",
    "---\n",
    "\n",
    "Repating same framework as above (copied the same code) but with **alpha set to 0.03**<br>\n",
    "This is what had the best performance!\n",
    "\n",
    "We've increased the number of iterations to 200"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# -------------------------------\n",
    "\n",
    "iters = 2000\n",
    "seeds = random.sample(range(10000), iters)\n",
    "# alpha = np.arange(0.01, 0.16, 0.01).tolist()\n",
    "alpha = [0.03]\n",
    "\n",
    "iterations = list(itertools.product(*[seeds, alpha]))\n",
    "\n",
    "# Store Results\n",
    "feature_coefs = []\n",
    "model_results = []  # alpha, mse, mae, r^2\n",
    "predictions = []\n",
    "target_idx = []\n",
    "mutual_info_reg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(iterations)):\n",
    "    \n",
    "    # alpha for the iteration\n",
    "    a = iterations[i][1]\n",
    "\n",
    "    # Split the data (seed based on i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_lasso, \n",
    "        df_target['api_delta'],\n",
    "        test_size=0.25,\n",
    "        random_state = iterations[i][0]\n",
    "    )\n",
    "\n",
    "    # Normalize data based on training\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform training data\n",
    "    X_train_scale = pd.DataFrame(scaler.transform(X_train))\n",
    "    X_train_scale.columns = X_train.columns\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_scale = pd.DataFrame(scaler.transform(X_test))\n",
    "    X_test_scale.columns = X_test.columns\n",
    "\n",
    "    # -----------------\n",
    "    # MODELING STARTS HERE\n",
    "    # -----------------\n",
    "    clf = linear_model.Lasso(alpha = a)\n",
    "    model = clf.fit(X_train_scale, y_train)\n",
    "    prediction_lasso = model.predict(X_test_scale)\n",
    "\n",
    "    # Mutual Information Regression\n",
    "    mir = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "    mir.fit(X_train_scale, y_train);\n",
    "\n",
    "    # model metrics\n",
    "    mse = mean_squared_error(y_test, prediction_lasso)\n",
    "    mae = mean_absolute_error(y_test, prediction_lasso)\n",
    "    r2 = r2_score(y_test, prediction_lasso)\n",
    "\n",
    "    # Store details\n",
    "    feature_coefs.append(model.coef_)\n",
    "    model_results.append([a, mse, mae, r2])\n",
    "    predictions.append(list(prediction_lasso))\n",
    "    target_idx.append(list(y_test.index))\n",
    "    mutual_info_reg.append(mir.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Importance\n",
    "df_lasso_results = pd.DataFrame(\n",
    "    model_results,\n",
    "    columns = ['alpha', 'mse', 'mae', 'r2']\n",
    ")\n",
    "\n",
    "# Feature Coefficiencts\n",
    "df_lasso_coefs = pd.DataFrame(\n",
    "    feature_coefs,\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "# Mutual Information Regression\n",
    "df_mir = pd.DataFrame(\n",
    "    mutual_info_reg,\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "# Combine them!\n",
    "df_results = pd.concat([df_lasso_results, df_lasso_coefs], axis=1)\n",
    "df_mir = pd.concat([df_lasso_results, df_mir], axis=1)"
   ]
  },
  {
   "source": [
    "### Logistic Regression Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               mae           r2\n",
       "count  2000.000000  2000.000000\n",
       "mean      0.691650     0.140453\n",
       "std       0.064494     0.092689\n",
       "min       0.509718    -0.378066\n",
       "25%       0.647471     0.091102\n",
       "50%       0.690732     0.154936\n",
       "75%       0.736046     0.205454\n",
       "max       0.953673     0.342623"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.691650</td>\n      <td>0.140453</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.064494</td>\n      <td>0.092689</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.509718</td>\n      <td>-0.378066</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.647471</td>\n      <td>0.091102</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.690732</td>\n      <td>0.154936</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.736046</td>\n      <td>0.205454</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.953673</td>\n      <td>0.342623</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "## Logistc Regression Results\n",
    "df_results[['mae', 'r2']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11.847"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "source": [
    "# Feature Importance\n",
    "# On average, only ~12 feaures are in each Logistic Regression Model!!\n",
    "(df_lasso_coefs != 0).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "api1_txfap           0.9970\n",
       "api2_txfap           0.9960\n",
       "api3_txfap           0.9275\n",
       "cdi5_txfap           0.8945\n",
       "sex                  0.7560\n",
       "cdi10_txfap          0.7110\n",
       "cdi9_txfap           0.6840\n",
       "cdi8_txfap           0.4715\n",
       "pbq14_txfap          0.4615\n",
       "csi8_txfap           0.3680\n",
       "promis_anx6_txfap    0.3315\n",
       "cdi23_txfap          0.2830\n",
       "pcsc10_txfap         0.2160\n",
       "csi14_txfap          0.2015\n",
       "prsleep3_txfap       0.1915\n",
       "cdi25_txfap          0.1845\n",
       "cdi19_txfap          0.1715\n",
       "prsleep7_txfap       0.1630\n",
       "csi19_txfap          0.1600\n",
       "pbq12_txfap          0.1535\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "# Feature Importance - How often does each feature have a non-zero weight\n",
    "# Printing the top 30!\n",
    "\n",
    "count_feature_has_coef = (df_lasso_coefs != 0).sum(axis=0)\n",
    "api_top_20 = (count_feature_has_coef / df_lasso_coefs.shape[0]).sort_values(ascending = False)[:20]\n",
    "api_top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "api2_txfap           0.143124\n",
       "api3_txfap           0.126913\n",
       "csi15_txfap          0.112312\n",
       "pbq2_txfap           0.111083\n",
       "api1_txfap           0.109738\n",
       "csi16_txfap          0.099148\n",
       "cdi22_txfap          0.093334\n",
       "cdi12_txfap          0.083830\n",
       "pcsc12_txfap         0.074329\n",
       "pcsc9_txfap          0.073086\n",
       "cdi13_txfap          0.059683\n",
       "pcsc10_txfap         0.058413\n",
       "fdi8_txfap           0.057237\n",
       "fdi12_txfap          0.055274\n",
       "csi20_txfap          0.055032\n",
       "promis_anx1_txfap    0.054405\n",
       "pbq5_txfap           0.053447\n",
       "csi7_txfap           0.052195\n",
       "pri12_txfap          0.046485\n",
       "cdi16_txfap          0.045525\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "source": [
    "# Feature Importance - How are they ranked based on Mutual Information Regression\n",
    "mir_top_20 = df_mir.iloc[:, 4:].mean().sort_values(ascending=False)[:20]\n",
    "mir_top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overlap -- Lasso in MIR: 4\nOverlap -- MIR in Lasso: 4\n"
     ]
    }
   ],
   "source": [
    "# Overlap between MIR and Lasso\n",
    "print(f'Overlap -- Lasso in MIR: {(api_top_20.index.isin(mir_top_20.index)).sum()}')\n",
    "print(f'Overlap -- MIR in Lasso: {(mir_top_20.index.isin(api_top_20.index)).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.418"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "# ~42% of the time, there is no information gain from study group\n",
    "df_mir['study_group'][df_mir['study_group'] == 0].count() / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    1164.000000\n",
       "mean        0.030104\n",
       "std         0.022505\n",
       "min         0.000028\n",
       "25%         0.012634\n",
       "50%         0.026120\n",
       "75%         0.042402\n",
       "max         0.127712\n",
       "Name: study_group, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "# When it is there, its a very low-ranked feature\n",
    "df_mir['study_group'][df_mir['study_group'] != 0].describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "source": [
    "## Logistic Regression - Remaining Features\n",
    "---\n",
    "\n",
    "Because we are seeing that each logistic regression is reducing the features pace to only ~12 features on average for `api_delta', let's see how that compares for the other two features.\n",
    "\n",
    "If there is a lot of overlap between top features we might be able to reduce the number of features quite a bit with little impact to overall performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS (1k Iterations, alpha = 0.03)\n",
    "# -------------------------------\n",
    "\n",
    "iters = 1000\n",
    "seeds = random.sample(range(10000), iters)\n",
    "alpha = [0.03]\n",
    "\n",
    "iterations = list(itertools.product(*[seeds, alpha]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSIGI BLOCK\n",
    "feature_coefs_csigi = []\n",
    "model_results_csigi = []  # alpha, mse, mae, r^2\n",
    "predictions_csigi = []\n",
    "target_idx_csigi = []\n",
    "\n",
    "for i in range(len(iterations)):\n",
    "\n",
    "    a = iterations[i][1]\n",
    "\n",
    "    # Split the data (seed based on i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_lasso, \n",
    "        df_target['csigi_delta'],\n",
    "        test_size=0.25,\n",
    "        random_state = iterations[i][0]\n",
    "    )\n",
    "\n",
    "    # Normalize data based on training\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform training data\n",
    "    X_train_scale = pd.DataFrame(scaler.transform(X_train))\n",
    "    X_train_scale.columns = X_train.columns\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_scale = pd.DataFrame(scaler.transform(X_test))\n",
    "    X_test_scale.columns = X_test.columns\n",
    "\n",
    "    # -----------------\n",
    "    # MODELING STARTS HERE\n",
    "    # -----------------\n",
    "    clf = linear_model.Lasso(alpha = a)\n",
    "    model = clf.fit(X_train_scale, y_train)\n",
    "    prediction_lasso = model.predict(X_test_scale)\n",
    "\n",
    "    # model metrics\n",
    "    mse = mean_squared_error(y_test, prediction_lasso)\n",
    "    mae = mean_absolute_error(y_test, prediction_lasso)\n",
    "    r2 = r2_score(y_test, prediction_lasso)\n",
    "\n",
    "    # Store details\n",
    "    feature_coefs_csigi.append(model.coef_)\n",
    "    model_results_csigi.append([a, mse, mae, r2])\n",
    "    predictions_csigi.append(list(prediction_lasso))\n",
    "    target_idx_csigi.append(list(y_test.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROMIS PAIN BLOCK\n",
    "feature_coefs_promis = []\n",
    "model_results_promis = []  # alpha, mse, mae, r^2\n",
    "predictions_promis = []\n",
    "target_idx_promis = []\n",
    "mutual_info_reg_promis = []\n",
    "\n",
    "for i in range(len(iterations)):\n",
    "\n",
    "    a = iterations[i][1]\n",
    "\n",
    "    # Split the data (seed based on i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_lasso, \n",
    "        df_target['api_delta'],\n",
    "        test_size=0.25,\n",
    "        random_state = iterations[i][0]\n",
    "    )\n",
    "\n",
    "    # Normalize data based on training\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform training data\n",
    "    X_train_scale = pd.DataFrame(scaler.transform(X_train))\n",
    "    X_train_scale.columns = X_train.columns\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_scale = pd.DataFrame(scaler.transform(X_test))\n",
    "    X_test_scale.columns = X_test.columns\n",
    "\n",
    "    # -----------------\n",
    "    # MODELING STARTS HERE\n",
    "    # -----------------\n",
    "    clf = linear_model.Lasso(alpha = a)\n",
    "    model = clf.fit(X_train_scale, y_train)\n",
    "    prediction_lasso = model.predict(X_test_scale)\n",
    "\n",
    "    # model metrics\n",
    "    mse = mean_squared_error(y_test, prediction_lasso)\n",
    "    mae = mean_absolute_error(y_test, prediction_lasso)\n",
    "    r2 = r2_score(y_test, prediction_lasso)\n",
    "\n",
    "    # Store details\n",
    "    feature_coefs_promis.append(model.coef_)\n",
    "    model_results_promis.append([a, mse, mae, r2])\n",
    "    predictions_promis.append(list(prediction_lasso))\n",
    "    target_idx_promis.append(list(y_test.index))"
   ]
  },
  {
   "source": [
    "### Results - CSI GI Symptoms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               mae           r2\n",
       "count  1000.000000  1000.000000\n",
       "mean      0.518699     0.163016\n",
       "std       0.053127     0.081624\n",
       "min       0.304568    -0.240176\n",
       "25%       0.484680     0.123180\n",
       "50%       0.518095     0.177009\n",
       "75%       0.553594     0.219166\n",
       "max       0.697730     0.371757"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.518699</td>\n      <td>0.163016</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.053127</td>\n      <td>0.081624</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.304568</td>\n      <td>-0.240176</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.484680</td>\n      <td>0.123180</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.518095</td>\n      <td>0.177009</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.553594</td>\n      <td>0.219166</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.697730</td>\n      <td>0.371757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "# CSI-GI Results (MAE)\n",
    "df_csigi_results = pd.DataFrame(\n",
    "    model_results_csigi,\n",
    "    columns = ['alpha', 'mse', 'mae', 'r2']\n",
    ")\n",
    "\n",
    "# Feature Coefficiencts\n",
    "df_coefs_csigi = pd.DataFrame(\n",
    "    feature_coefs_csigi,\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "df_csigi_results[['mae', 'r2']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average number of features used in each Logistic regression model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10.142"
      ]
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "# Feature Importance\n",
    "print('Average number of features used in each Logistic regression model') \n",
    "(df_coefs_csigi != 0).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "csi21_txfap          1.000\n",
       "csi12_txfap          0.967\n",
       "csi15_txfap          0.953\n",
       "csi14_txfap          0.904\n",
       "cdi13_txfap          0.786\n",
       "cdi10_txfap          0.717\n",
       "sex                  0.701\n",
       "cdi19_txfap          0.546\n",
       "csi13_txfap          0.459\n",
       "csi22_txfap          0.326\n",
       "cdi7_txfap           0.313\n",
       "csi20_txfap          0.288\n",
       "study_group          0.259\n",
       "cdi8_txfap           0.252\n",
       "pcsc11_txfap         0.246\n",
       "cdi21_txfap          0.156\n",
       "csi3_txfap           0.144\n",
       "cdi1_txfap           0.121\n",
       "promis_anx6_txfap    0.110\n",
       "promis_anx5_txfap    0.101\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "source": [
    "# Top 30 features from CSIGI\n",
    "count_feature_has_coef = (df_coefs_csigi != 0).sum(axis=0)\n",
    "csigi_top_20 = (count_feature_has_coef / df_coefs_csigi.shape[0]).sort_values(ascending = False)[:20]\n",
    "csigi_top_20"
   ]
  },
  {
   "source": [
    "### Results - PROMIS Pain Symptoms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               mse          mae           r2\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean      0.730198     0.692686     0.143508\n",
       "std       0.118764     0.063913     0.092872\n",
       "min       0.370167     0.506037    -0.327527\n",
       "25%       0.645731     0.648575     0.097698\n",
       "50%       0.724497     0.691759     0.159436\n",
       "75%       0.808983     0.735459     0.206890\n",
       "max       1.159192     0.882344     0.337685"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.730198</td>\n      <td>0.692686</td>\n      <td>0.143508</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.118764</td>\n      <td>0.063913</td>\n      <td>0.092872</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.370167</td>\n      <td>0.506037</td>\n      <td>-0.327527</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.645731</td>\n      <td>0.648575</td>\n      <td>0.097698</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.724497</td>\n      <td>0.691759</td>\n      <td>0.159436</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.808983</td>\n      <td>0.735459</td>\n      <td>0.206890</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.159192</td>\n      <td>0.882344</td>\n      <td>0.337685</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "# CSI-GI Results (MSE)\n",
    "df_promis_results = pd.DataFrame(\n",
    "    model_results_promis,\n",
    "    columns = ['alpha', 'mse', 'mae', 'r2']\n",
    ")\n",
    "\n",
    "# Feature Coefficiencts\n",
    "df_coefs_promis = pd.DataFrame(\n",
    "    feature_coefs_promis,\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "df_promis_results[['mse', 'mae', 'r2']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average number of features used in each Logistic regression model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11.81"
      ]
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "source": [
    "# Feature Importance\n",
    "print('Average number of features used in each Logistic regression model') \n",
    "(df_coefs_promis != 0).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "api1_txfap           0.998\n",
       "api2_txfap           0.997\n",
       "api3_txfap           0.933\n",
       "cdi5_txfap           0.876\n",
       "sex                  0.731\n",
       "cdi10_txfap          0.706\n",
       "cdi9_txfap           0.682\n",
       "cdi8_txfap           0.473\n",
       "pbq14_txfap          0.466\n",
       "promis_anx6_txfap    0.358\n",
       "csi8_txfap           0.355\n",
       "cdi23_txfap          0.267\n",
       "pcsc10_txfap         0.221\n",
       "csi14_txfap          0.210\n",
       "prsleep7_txfap       0.204\n",
       "prsleep3_txfap       0.187\n",
       "cdi25_txfap          0.184\n",
       "cdi19_txfap          0.161\n",
       "pbq12_txfap          0.161\n",
       "csi19_txfap          0.161\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "source": [
    "# Top 30 features from PROMIS\n",
    "count_feature_has_coef = (df_coefs_promis != 0).sum(axis=0)\n",
    "promis_top_20 = (count_feature_has_coef / df_coefs_promis.shape[0]).sort_values(ascending = False)[:20]\n",
    "promis_top_20"
   ]
  },
  {
   "source": [
    "## Logistic Regression - Only Top 10 Features\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(api_top_20.index.values)\n",
    "features.extend(csigi_top_20.index.values)\n",
    "features.extend(promis_top_20.index.values)\n",
    "\n",
    "# Reduce to unique (only 34)\n",
    "features = list(set(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS (1k Iterations, alpha = 0.03)\n",
    "# -------------------------------\n",
    "iters = 1000\n",
    "seeds = random.sample(range(10000), iters)\n",
    "alpha = [0.03]\n",
    "\n",
    "iterations = list(itertools.product(*[seeds, alpha]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = ['api_delta', 'csigi_delta', 'cprinter_delta']\n",
    "df_lasso_reduced = df_lasso[features] # reduce to our 34 features\n",
    "\n",
    "\n",
    "feature_coefs_final = []\n",
    "model_results_final = []  # mse, mae\n",
    "predictions_final = []\n",
    "\n",
    "# Same loop as before, but for each target\n",
    "for target in outcome_var:\n",
    "    for i in range(len(iterations)):\n",
    "        \n",
    "        # iteration alpha\n",
    "        a = iterations[i][1]\n",
    "\n",
    "        # Split the data (seed based on i)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_lasso, \n",
    "            df_target[target],\n",
    "            test_size=0.25,\n",
    "            random_state = iterations[i][0]\n",
    "        )\n",
    "\n",
    "        # Normalize data based on training\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        # Transform training data\n",
    "        X_train_scale = pd.DataFrame(scaler.transform(X_train))\n",
    "        X_train_scale.columns = X_train.columns\n",
    "\n",
    "        # Transform test data\n",
    "        X_test_scale = pd.DataFrame(scaler.transform(X_test))\n",
    "        X_test_scale.columns = X_test.columns\n",
    "\n",
    "        # -----------------\n",
    "        # MODELING STARTS HERE\n",
    "        # -----------------\n",
    "        clf = linear_model.Lasso(alpha = a)\n",
    "        model = clf.fit(X_train_scale, y_train)\n",
    "        prediction_lasso = model.predict(X_test_scale)\n",
    "\n",
    "        # model metrics\n",
    "        mse = mean_squared_error(y_test, prediction_lasso)\n",
    "        mae = mean_absolute_error(y_test, prediction_lasso)\n",
    "\n",
    "        # Store details\n",
    "        feature_coefs_final.append(model.coef_)\n",
    "        model_results_final.append([mse, mae])\n",
    "        predictions_final.append(list(prediction_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "API Results\nmse    0.722068\nmae    0.689555\ndtype: float64\n\nCSIGI Results\nmse    0.429253\nmae    0.520293\ndtype: float64\n\nPROMIS Results\nmse    72.453160\nmae     6.467261\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CSI-GI Results (MAE)\n",
    "df_results_final = pd.DataFrame(\n",
    "    model_results_final,\n",
    "    columns = ['mse', 'mae']\n",
    ")\n",
    "\n",
    "print('API Results')\n",
    "print(df_results_final[:1000].mean())\n",
    "\n",
    "print('\\nCSIGI Results')\n",
    "print(df_results_final[1000:2000].mean())\n",
    "\n",
    "print('\\nPROMIS Results')\n",
    "print(df_results_final[2000:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Coefficiencts\n",
    "df_coefs_final = pd.DataFrame(\n",
    "    feature_coefs_final,\n",
    "    columns = X_train.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "API Top 10 (absoulte value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "api2_txfap           0.556119\n",
       "api1_txfap           0.456450\n",
       "api3_txfap           0.274890\n",
       "cdi5_txfap           0.229689\n",
       "cdi9_txfap           0.085321\n",
       "cdi10_txfap          0.081388\n",
       "cdi8_txfap           0.070331\n",
       "sex                  0.067440\n",
       "pbq14_txfap          0.042464\n",
       "promis_anx6_txfap    0.038185\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 250
    }
   ],
   "source": [
    "print('API Top 10 (absolute value)')\n",
    "df_coefs_final[:1000].mean().abs().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CSI GI Top 10 (absolute value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "csi21_txfap    0.455350\n",
       "csi15_txfap    0.222690\n",
       "csi12_txfap    0.219587\n",
       "csi14_txfap    0.148602\n",
       "cdi13_txfap    0.088650\n",
       "cdi10_txfap    0.071913\n",
       "sex            0.052579\n",
       "cdi19_txfap    0.043887\n",
       "csi13_txfap    0.038172\n",
       "cdi7_txfap     0.025215\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "source": [
    "print('CSI GI Top 10 (absolute value)')\n",
    "df_coefs_final[1000:2000].mean().abs().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PROMIS Top 10 (absolute value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cdi1_txfap     5.957673\n",
       "pbq15_txfap    5.291473\n",
       "cdi24_txfap    4.922545\n",
       "cdi25_txfap    4.669209\n",
       "csi18_txfap    4.399131\n",
       "cdi22_txfap    4.022724\n",
       "fdi8_txfap     3.777352\n",
       "cdi23_txfap    3.610868\n",
       "fdi9_txfap     3.079780\n",
       "pbq10_txfap    2.959566\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 253
    }
   ],
   "source": [
    "print('PROMIS Top 10 (absolute value)')\n",
    "df_coefs_final[2000:].mean().abs().sort_values(ascending=False)[:10]"
   ]
  }
 ]
}